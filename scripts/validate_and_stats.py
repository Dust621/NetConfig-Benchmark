#!/usr/bin/env python3
"""
åä¸ºNE40Eæ•°æ®éªŒè¯å’Œç»Ÿè®¡è„šæœ¬
éªŒè¯ç”Ÿæˆçš„jsonæ–‡ä»¶è´¨é‡å¹¶ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
"""

import json
import os
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Any

class DataValidator:
    def __init__(self, data_dir: str = "datasets/Huawei/NE40E_examples"):
        self.data_dir = Path(data_dir)
        self.stats = {
            "total_files": 0,
            "valid_files": 0,
            "invalid_files": [],
            "categories": {},
            "device_types": Counter(),
            "config_lengths": [],
            "step_counts": [],
            "topology_lengths": [],
            "requirement_lengths": [],
            "image_counts": []
        }
    
    def validate_json_structure(self, data: Dict[str, Any], filename: str) -> bool:
        """éªŒè¯JSONç»“æ„æ˜¯å¦ç¬¦åˆè¦æ±‚"""
        required_fields = ["topology", "requirement", "steps", "configs"]
        
        for field in required_fields:
            if field not in data:
                print(f"  âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False
        
        # éªŒè¯å­—æ®µç±»å‹
        if not isinstance(data["topology"], str):
            print(f"  âŒ topologyå­—æ®µåº”ä¸ºå­—ç¬¦ä¸²")
            return False
        
        if not isinstance(data["requirement"], str):
            print(f"  âŒ requirementå­—æ®µåº”ä¸ºå­—ç¬¦ä¸²")
            return False
        
        if not isinstance(data["steps"], list):
            print(f"  âŒ stepså­—æ®µåº”ä¸ºåˆ—è¡¨")
            return False
        
        if not isinstance(data["configs"], dict):
            print(f"  âŒ configså­—æ®µåº”ä¸ºå­—å…¸")
            return False
        
        # éªŒè¯å†…å®¹è´¨é‡
        if len(data["topology"].strip()) < 10:
            print(f"  âš ï¸  topologyå†…å®¹è¿‡çŸ­")
        
        if len(data["requirement"].strip()) < 10:
            print(f"  âš ï¸  requirementå†…å®¹è¿‡çŸ­")
        
        if len(data["steps"]) == 0:
            print(f"  âš ï¸  æ²¡æœ‰é…ç½®æ­¥éª¤")
        
        if len(data["configs"]) == 0:
            print(f"  âš ï¸  æ²¡æœ‰è®¾å¤‡é…ç½®")
        
        return True
    
    def collect_statistics(self, data: Dict[str, Any], category: str):
        """æ”¶é›†ç»Ÿè®¡ä¿¡æ¯"""
        # è®¾å¤‡ç±»å‹ç»Ÿè®¡
        for device_name in data["configs"].keys():
            self.stats["device_types"][device_name] += 1
        
        # é…ç½®é•¿åº¦ç»Ÿè®¡
        total_config_length = sum(len(config) for config in data["configs"].values())
        self.stats["config_lengths"].append(total_config_length)
        
        # æ­¥éª¤æ•°é‡ç»Ÿè®¡
        self.stats["step_counts"].append(len(data["steps"]))
        
        # æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
        self.stats["topology_lengths"].append(len(data["topology"]))
        self.stats["requirement_lengths"].append(len(data["requirement"]))
        
        # å›¾ç‰‡æ•°é‡ç»Ÿè®¡
        image_count = len(data.get("related_images", []))
        self.stats["image_counts"].append(image_count)
        
        # ç±»åˆ«ç»Ÿè®¡
        if category not in self.stats["categories"]:
            self.stats["categories"][category] = {
                "file_count": 0,
                "device_count": 0,
                "total_config_length": 0,
                "avg_steps": 0,
                "avg_topology_length": 0,
                "avg_requirement_length": 0
            }
        
        cat_stats = self.stats["categories"][category]
        cat_stats["file_count"] += 1
        cat_stats["device_count"] += len(data["configs"])
        cat_stats["total_config_length"] += total_config_length
    
    def validate_all_files(self):
        """éªŒè¯æ‰€æœ‰æ–‡ä»¶"""
        print("ğŸ” å¼€å§‹éªŒè¯æ•°æ®æ–‡ä»¶...")
        
        for category_dir in self.data_dir.iterdir():
            if not category_dir.is_dir() or category_dir.name.startswith('_'):
                continue
            
            category_name = category_dir.name
            print(f"\nğŸ“ éªŒè¯ç±»åˆ«: {category_name}")
            
            for json_file in category_dir.glob("*.json"):
                if json_file.name.startswith('_'):
                    continue
                
                self.stats["total_files"] += 1
                print(f"  ğŸ“„ éªŒè¯æ–‡ä»¶: {json_file.name}")
                
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    if self.validate_json_structure(data, json_file.name):
                        self.stats["valid_files"] += 1
                        self.collect_statistics(data, category_name)
                        print(f"    âœ… éªŒè¯é€šè¿‡")
                    else:
                        self.stats["invalid_files"].append(str(json_file))
                        print(f"    âŒ éªŒè¯å¤±è´¥")
                
                except json.JSONDecodeError as e:
                    self.stats["invalid_files"].append(str(json_file))
                    print(f"    âŒ JSONè§£æé”™è¯¯: {e}")
                except Exception as e:
                    self.stats["invalid_files"].append(str(json_file))
                    print(f"    âŒ å…¶ä»–é”™è¯¯: {e}")
    
    def calculate_summary_stats(self):
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        if self.stats["config_lengths"]:
            self.stats["avg_config_length"] = sum(self.stats["config_lengths"]) / len(self.stats["config_lengths"])
            self.stats["max_config_length"] = max(self.stats["config_lengths"])
            self.stats["min_config_length"] = min(self.stats["config_lengths"])
        
        if self.stats["step_counts"]:
            self.stats["avg_steps"] = sum(self.stats["step_counts"]) / len(self.stats["step_counts"])
            self.stats["max_steps"] = max(self.stats["step_counts"])
            self.stats["min_steps"] = min(self.stats["step_counts"])
        
        if self.stats["topology_lengths"]:
            self.stats["avg_topology_length"] = sum(self.stats["topology_lengths"]) / len(self.stats["topology_lengths"])
        
        if self.stats["requirement_lengths"]:
            self.stats["avg_requirement_length"] = sum(self.stats["requirement_lengths"]) / len(self.stats["requirement_lengths"])
        
        if self.stats["image_counts"]:
            self.stats["avg_images"] = sum(self.stats["image_counts"]) / len(self.stats["image_counts"])
            self.stats["total_images"] = sum(self.stats["image_counts"])
        
        # è®¡ç®—å„ç±»åˆ«å¹³å‡å€¼
        for category, cat_stats in self.stats["categories"].items():
            if cat_stats["file_count"] > 0:
                cat_stats["avg_steps"] = sum(self.stats["step_counts"]) / len(self.stats["step_counts"])
                cat_stats["avg_topology_length"] = sum(self.stats["topology_lengths"]) / len(self.stats["topology_lengths"])
                cat_stats["avg_requirement_length"] = sum(self.stats["requirement_lengths"]) / len(self.stats["requirement_lengths"])
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡æŠ¥å‘Š")
        print("="*60)
        
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  â€¢ æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"  â€¢ æœ‰æ•ˆæ–‡ä»¶æ•°: {self.stats['valid_files']}")
        print(f"  â€¢ æ— æ•ˆæ–‡ä»¶æ•°: {len(self.stats['invalid_files'])}")
        print(f"  â€¢ éªŒè¯é€šè¿‡ç‡: {self.stats['valid_files']/self.stats['total_files']*100:.1f}%")
        
        if hasattr(self.stats, 'avg_config_length'):
            print(f"\nğŸ“ é…ç½®ç»Ÿè®¡:")
            print(f"  â€¢ å¹³å‡é…ç½®é•¿åº¦: {self.stats['avg_config_length']:.0f} å­—ç¬¦")
            print(f"  â€¢ æœ€å¤§é…ç½®é•¿åº¦: {self.stats['max_config_length']} å­—ç¬¦")
            print(f"  â€¢ æœ€å°é…ç½®é•¿åº¦: {self.stats['min_config_length']} å­—ç¬¦")
        
        if hasattr(self.stats, 'avg_steps'):
            print(f"\nğŸ“‹ æ­¥éª¤ç»Ÿè®¡:")
            print(f"  â€¢ å¹³å‡é…ç½®æ­¥éª¤æ•°: {self.stats['avg_steps']:.1f}")
            print(f"  â€¢ æœ€å¤šé…ç½®æ­¥éª¤æ•°: {self.stats['max_steps']}")
            print(f"  â€¢ æœ€å°‘é…ç½®æ­¥éª¤æ•°: {self.stats['min_steps']}")
        
        if hasattr(self.stats, 'avg_topology_length'):
            print(f"\nğŸŒ å†…å®¹ç»Ÿè®¡:")
            print(f"  â€¢ å¹³å‡æ‹“æ‰‘æè¿°é•¿åº¦: {self.stats['avg_topology_length']:.0f} å­—ç¬¦")
            print(f"  â€¢ å¹³å‡éœ€æ±‚æè¿°é•¿åº¦: {self.stats['avg_requirement_length']:.0f} å­—ç¬¦")
        
        if hasattr(self.stats, 'total_images'):
            print(f"\nğŸ–¼ï¸  å›¾ç‰‡ç»Ÿè®¡:")
            print(f"  â€¢ æ€»å›¾ç‰‡æ•°: {self.stats['total_images']}")
            print(f"  â€¢ å¹³å‡æ¯ä¸ªå®éªŒå›¾ç‰‡æ•°: {self.stats['avg_images']:.1f}")
        
        print(f"\nğŸ“‚ åˆ†ç±»ç»Ÿè®¡:")
        for category, cat_stats in self.stats["categories"].items():
            print(f"  â€¢ {category}: {cat_stats['file_count']} ä¸ªæ–‡ä»¶, {cat_stats['device_count']} ä¸ªè®¾å¤‡é…ç½®")
        
        print(f"\nğŸ–¥ï¸  è®¾å¤‡ç±»å‹ç»Ÿè®¡ (å‰10å):")
        for device, count in self.stats["device_types"].most_common(10):
            print(f"  â€¢ {device}: {count} æ¬¡")
        
        if self.stats["invalid_files"]:
            print(f"\nâŒ æ— æ•ˆæ–‡ä»¶åˆ—è¡¨:")
            for invalid_file in self.stats["invalid_files"]:
                print(f"  â€¢ {invalid_file}")
    
    def save_statistics(self):
        """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯åˆ°æ–‡ä»¶"""
        stats_file = self.data_dir / "_validation_report.json"
        
        # è½¬æ¢Counterå¯¹è±¡ä¸ºæ™®é€šå­—å…¸
        stats_copy = dict(self.stats)
        stats_copy["device_types"] = dict(self.stats["device_types"])
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats_copy, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {stats_file}")
    
    def run_validation(self):
        """è¿è¡Œå®Œæ•´éªŒè¯æµç¨‹"""
        self.validate_all_files()
        self.calculate_summary_stats()
        self.print_statistics()
        self.save_statistics()
        
        print(f"\nğŸ‰ éªŒè¯å®Œæˆ!")
        print(f"  â€¢ å…±å¤„ç† {self.stats['total_files']} ä¸ªæ–‡ä»¶")
        print(f"  â€¢ éªŒè¯é€šè¿‡ç‡: {self.stats['valid_files']/self.stats['total_files']*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    validator = DataValidator()
    validator.run_validation()

if __name__ == "__main__":
    main()