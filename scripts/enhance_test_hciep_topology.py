#!/usr/bin/env python3
"""
å¢å¼ºTESTå’ŒHCIEPç›®å½•ä¸‹JSONæ–‡ä»¶çš„topologyæè¿°
åŸºäºenhance_topology_with_images.pyï¼Œä¸“é—¨å¤„ç†TESTå’ŒHCIEPç›®å½•
"""

import os
import json
import base64
from pathlib import Path
from typing import Dict, List, Optional, Union
import time
import httpx
from openai import OpenAI
import requests

def extract_think_content(text):
    """æå–<think>æ ‡ç­¾å†…å®¹"""
    import re
    match = re.search(r"<think>(.*?)</think>", text, re.DOTALL)
    if match:
        reasoning_content = match.group(1).strip()
        response_content = (text[:match.start()] + text[match.end():]).strip()
        return response_content, reasoning_content
    return text, None

class MultimodalLLMClient:
    def __init__(self, provider: str = "claude", api_key: str = None, base_url: str = None, model: str = None):
        self.provider = provider
        self.api_key = api_key
        self.base_url = base_url
        self.model = model

        # é…ç½®ä»£ç†æ”¯æŒ
        http_proxy = os.getenv("PES_HTTP_PROXY") or os.getenv("HTTP_PROXY")
        https_proxy = os.getenv("PES_HTTPS_PROXY") or os.getenv("HTTPS_PROXY")

        client_kwargs = {
            "api_key": self.api_key,
            "base_url": self.base_url
        }

        # å¦‚æœæœ‰ä»£ç†è®¾ç½®ï¼Œæ·»åŠ ä»£ç†é…ç½®
        if http_proxy or https_proxy:
            proxy_url = https_proxy if https_proxy else http_proxy
            client_kwargs["http_client"] = httpx.Client(proxy=proxy_url)
            print(f"ä½¿ç”¨ä»£ç†: {proxy_url}")
        
        if provider == "openai":
            self.api_key = api_key or os.getenv("OPENAI_API_KEY")
            self.base_url = base_url or "https://api.openai.com/v1"
            self.model = model or "gpt-4o"
            self.client = OpenAI(**client_kwargs)
            
        elif provider == "claude":
            self.api_key = api_key or "sk-GdmMOsWLYBdMwUBwJsaZGKOhM0k7cfuonqzTPvzLVVo1N4SL"
            self.model = model or "claude-sonnet-4-20250514"
            self.base_url = base_url or "https://chat.cloudapi.vip/v1/"
            self.client = OpenAI(**client_kwargs)
                
        elif provider == "gemini":
            self.api_key = api_key or os.getenv("GOOGLE_API_KEY") 
            self.model = model or "gemini-1.5-pro"
            self.base_url = "https://generativelanguage.googleapis.com/v1beta"
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {provider}")
    
    def encode_image(self, image_path: str) -> str:
        """å°†å›¾ç‰‡ç¼–ç ä¸ºbase64"""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            print(f"å›¾ç‰‡ç¼–ç å¤±è´¥ {image_path}: {e}")
            return None
    
    def analyze_topology_with_image(self, json_data: Dict, image_paths: List[str]) -> Optional[str]:
        """ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹åˆ†æç½‘ç»œæ‹“æ‰‘å›¾å¹¶å¢å¼ºæè¿°"""
        
        if not image_paths:
            return None
        
        # æ„å»ºprompt - é’ˆå¯¹TESTå’ŒHCIEPæ•°æ®ä¼˜åŒ–
        current_topology = json_data.get("topology", "")
        requirement = json_data.get("requirement", "")
        configs = json_data.get("configs", {})
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç½‘ç»œå·¥ç¨‹ä¸“å®¶ï¼Œè¯·æ ¹æ®æä¾›çš„ç½‘ç»œæ‹“æ‰‘å›¾ï¼Œå¢å¼ºå’Œå®Œå–„ä»¥ä¸‹ç½‘ç»œæ‹“æ‰‘æè¿°ã€‚

å½“å‰æ‹“æ‰‘æè¿°ï¼š
{current_topology}

ç»„ç½‘éœ€æ±‚ï¼š
{requirement}

é…ç½®æ–‡ä»¶ï¼š
{configs}

è¯·ä»”ç»†åˆ†æå›¾ç‰‡ä¸­çš„ç½‘ç»œæ‹“æ‰‘ç»“æ„ï¼ŒåŒ…æ‹¬ï¼š
1. è®¾å¤‡ç±»å‹å’Œæ•°é‡ï¼ˆè·¯ç”±å™¨ã€äº¤æ¢æœºç­‰ï¼‰
2. è®¾å¤‡ä¹‹é—´çš„è¿æ¥å…³ç³»å’Œæ¥å£
3. ç½‘ç»œåˆ†æ®µå’ŒVLANä¿¡æ¯
4. IPåœ°å€åˆ†é…å’Œå­ç½‘åˆ’åˆ†
5. åè®®é…ç½®åŒºåŸŸï¼ˆå¦‚OSPFåŒºåŸŸã€BGP ASç­‰ï¼‰
6. ç‰¹æ®Šé…ç½®ï¼ˆå¦‚è™šè¿æ¥ã€æ±‡èšé“¾è·¯ç­‰ï¼‰

æ³¨æ„ï¼šå¦‚æœå›¾ç‰‡ä¸­çš„ä¿¡æ¯æ‚ç³…ï¼Œæ— æ³•åˆ¤æ–­æ¥å£åœ°å€æˆ–è¿æ¥æƒ…å†µï¼Œè¯·å‚è€ƒé…ç½®æ–‡ä»¶ä¸­å¯¹åº”è®¾å¤‡çš„å…·ä½“é…ç½®ï¼Œç¡®ä¿æ‹“æ‰‘ä¿¡æ¯çš„æ­£ç¡®æ€§ã€‚

åŸºäºå›¾ç‰‡å†…å®¹ï¼Œæä¾›ä¸€ä¸ªæ›´è¯¦ç»†ã€å‡†ç¡®çš„ç½‘ç»œæ‹“æ‰‘æè¿°ã€‚ä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼Œé‡ç‚¹æè¿°ç½‘ç»œçš„é€»è¾‘ç»“æ„å’Œç‰©ç†è¿æ¥ã€‚

è¯·ç›´æ¥è¿”å›å¢å¼ºåçš„æ‹“æ‰‘æè¿°ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—(è¯·ä¿è¯è¿”å›çš„æ‹“æ‰‘æè¿°çš„æ­£ç¡®æ€§å’Œç®€æ´æ€§)ï¼š"""

        try:
            if self.provider == "openai":
                return self._call_openai_vision(prompt, image_paths)
            elif self.provider == "claude":
                return self._call_openai_vision(prompt, image_paths)
            elif self.provider == "gemini":
                return self._call_gemini_vision(prompt, image_paths)
        except Exception as e:
            print(f"å¤šæ¨¡æ€è°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _call_openai_vision(self, prompt: str, image_paths: List[str]) -> Optional[str]:
        """è°ƒç”¨OpenAI Vision API"""
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt}
                ]
            }
        ]
        
        # æ·»åŠ å›¾ç‰‡
        for image_path in image_paths[:3]:  # é™åˆ¶æœ€å¤š3å¼ å›¾ç‰‡
            base64_image = self.encode_image(image_path)
            if base64_image:
                messages[0]["content"].append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{base64_image}",
                        "detail": "high"
                    }
                })
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.3,
            max_tokens=1500
        )
        
        return response.choices[0].message.content.strip()
    
    def _call_gemini_vision(self, prompt: str, image_paths: List[str]) -> Optional[str]:
        """è°ƒç”¨Gemini Vision API"""
        url = f"{self.base_url}/models/{self.model}:generateContent?key={self.api_key}"
        
        parts = [{"text": prompt}]
        
        # æ·»åŠ å›¾ç‰‡
        for image_path in image_paths[:3]:  # é™åˆ¶æœ€å¤š3å¼ å›¾ç‰‡
            base64_image = self.encode_image(image_path)
            if base64_image:
                parts.append({
                    "inline_data": {
                        "mime_type": "image/png",
                        "data": base64_image
                    }
                })
        
        data = {
            "contents": [{"parts": parts}],
            "generationConfig": {
                "temperature": 0.3,
                "maxOutputTokens": 1500
            }
        }
        
        response = requests.post(url, json=data)
        if response.status_code == 200:
            result = response.json()
            if "candidates" in result and result["candidates"]:
                return result["candidates"][0]["content"]["parts"][0]["text"].strip()
        else:
            print(f"Gemini APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
        
        return None

class TestHciepTopologyEnhancer:
    def __init__(self, provider: str = "claude", api_key: str = None, base_url: str = None, model: str = None):
        self.llm_client = MultimodalLLMClient(
            provider=provider,
            api_key=api_key,
            base_url=base_url,
            model=model
        )
        self.base_dir = Path("datasets/Huawei")
        
    def find_corresponding_image(self, json_path: Path) -> List[str]:
        """æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶"""
        image_paths = []
        
        # è·å–JSONæ–‡ä»¶çš„åŸºæœ¬åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
        json_name = json_path.stem
        
        # æ ¹æ®ä¸åŒç›®å½•æŸ¥æ‰¾å›¾ç‰‡
        if "TEST" in str(json_path):
            # TESTç›®å½•çš„å›¾ç‰‡åœ¨img/å­ç›®å½•ä¸‹
            img_dir = json_path.parent / "img"
            possible_image = img_dir / f"{json_name}.png"
        elif "HCIEP" in str(json_path):
            # HCIEPç›®å½•çš„å›¾ç‰‡åœ¨imgs/å­ç›®å½•ä¸‹
            img_dir = json_path.parent / "imgs"
            possible_image = img_dir / f"{json_name}.png"
        else:
            return image_paths
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        if possible_image.exists():
            image_paths.append(str(possible_image))
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°å¯¹åº”å›¾ç‰‡: {possible_image}")
        
        return image_paths
        
    def enhance_single_json(self, json_path: Path) -> bool:
        """å¢å¼ºå•ä¸ªJSONæ–‡ä»¶çš„æ‹“æ‰‘æè¿°"""
        try:
            # è¯»å–JSONæ–‡ä»¶
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
            image_paths = self.find_corresponding_image(json_path)
            
            if not image_paths:
                print(f"â­ï¸  {json_path.name}: æ²¡æœ‰æ‰¾åˆ°å¯¹åº”å›¾ç‰‡ï¼Œè·³è¿‡å¢å¼º")
                return True
            
            print(f"ğŸ–¼ï¸  {json_path.name}: åˆ†æ {len(image_paths)} å¼ å›¾ç‰‡...")
            
            # è°ƒç”¨å¤šæ¨¡æ€æ¨¡å‹å¢å¼ºæ‹“æ‰‘æè¿°
            enhanced_topology = self.llm_client.analyze_topology_with_image(data, image_paths)
            
            if enhanced_topology and enhanced_topology != data.get("topology", ""):
                # ä¿å­˜åŸå§‹æè¿°
                if "topology" in data and data["topology"]:
                    data["topology_original"] = data["topology"]
                
                # æ›´æ–°å¢å¼ºåçš„æè¿°
                data["topology"] = enhanced_topology
                
                # ä¿å­˜æ›´æ–°åçš„JSON
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                
                print(f"âœ… {json_path.name}: æ‹“æ‰‘æè¿°å·²å¢å¼º")
                print(f"   åŸå§‹é•¿åº¦: {len(data.get('topology_original', ''))} å­—ç¬¦")
                print(f"   å¢å¼ºé•¿åº¦: {len(enhanced_topology)} å­—ç¬¦")
                return True
            else:
                print(f"âš ï¸  {json_path.name}: æ— æ³•ç”Ÿæˆå¢å¼ºæè¿°æˆ–å†…å®¹ç›¸åŒ")
                return False
                
        except Exception as e:
            print(f"âŒ {json_path.name}: å¤„ç†å¤±è´¥ - {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def enhance_directory(self, json_dir: Path, limit: int = None):
        """å¢å¼ºæ•´ä¸ªç›®å½•ä¸­çš„JSONæ–‡ä»¶"""
        json_files = list(json_dir.glob("**/*.json"))
        
        # è¿‡æ»¤æ‰ä¸ç›¸å…³çš„JSONæ–‡ä»¶
        json_files = [f for f in json_files if not f.name.startswith("_")]
        
        if limit:
            json_files = json_files[:limit]
        
        enhanced_count = 0
        failed_count = 0
        
        print(f"ğŸš€ å¼€å§‹å¢å¼º {len(json_files)} ä¸ªJSONæ–‡ä»¶çš„æ‹“æ‰‘æè¿°")
        print("=" * 60)
        
        for json_file in json_files:
            success = self.enhance_single_json(json_file)
            if success:
                enhanced_count += 1
            else:
                failed_count += 1
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            time.sleep(2)
        
        print("=" * 60)
        print(f"ğŸ‰ å¢å¼ºå®Œæˆ!")
        print(f"   æˆåŠŸ: {enhanced_count} ä¸ªæ–‡ä»¶")
        print(f"   å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
    
    def enhance_both_directories(self, limit: int = None):
        """å¢å¼ºTESTå’ŒHCIEPä¸¤ä¸ªç›®å½•"""
        test_dir = self.base_dir / "TEST"
        hciep_dir = self.base_dir / "HCIEP"
        
        directories = []
        if test_dir.exists():
            directories.append(("TEST", test_dir))
        if hciep_dir.exists():
            directories.append(("HCIEP", hciep_dir))
        
        if not directories:
            print("âŒ æœªæ‰¾åˆ°TESTæˆ–HCIEPç›®å½•")
            return
        
        for dir_name, dir_path in directories:
            print(f"\nğŸ”„ å¤„ç† {dir_name} ç›®å½•...")
            print("=" * 50)
            self.enhance_directory(dir_path, limit)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å¢å¼ºTESTå’ŒHCIEPç›®å½•ä¸‹JSONæ–‡ä»¶çš„æ‹“æ‰‘æè¿°")
    parser.add_argument("--provider", choices=["openai", "claude", "gemini"], 
                       default="claude", help="å¤šæ¨¡æ€LLMæä¾›å•†")
    parser.add_argument("--api-key", help="APIå¯†é’¥", default="sk-GdmMOsWLYBdMwUBwJsaZGKOhM0k7cfuonqzTPvzLVVo1N4SL")
    parser.add_argument("--base-url", help="APIåŸºç¡€URLï¼ˆå¯é€‰ï¼‰", default="https://chat.cloudapi.vip/v1/")
    parser.add_argument("--model", help="ä½¿ç”¨çš„æ¨¡å‹", default="claude-sonnet-4-20250514")
    parser.add_argument("--limit", type=int, help="é™åˆ¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    parser.add_argument("--single-file", help="å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆæµ‹è¯•ç”¨ï¼‰")
    parser.add_argument("--directory", choices=["TEST", "HCIEP", "both"], default="both",
                       help="é€‰æ‹©è¦å¤„ç†çš„ç›®å½•")
    
    args = parser.parse_args()
    
    # æ ¹æ®æä¾›å•†è®¾ç½®é»˜è®¤å€¼
    if args.provider == "openai":
        default_api_key_env = "OPENAI_API_KEY"
        default_model = "gpt-4o"
        api_description = "OpenAI APIå¯†é’¥"
    elif args.provider == "claude":
        default_api_key_env = "ANTHROPIC_API_KEY"
        default_model = "claude-sonnet-4-20250514"
        api_description = "Anthropic APIå¯†é’¥"
    elif args.provider == "gemini":
        default_api_key_env = "GOOGLE_API_KEY"
        default_model = "gemini-1.5-pro"
        api_description = "Google APIå¯†é’¥"
    
    # è·å–APIå¯†é’¥
    api_key = args.api_key or os.getenv(default_api_key_env)
    if not api_key:
        print(f"âŒ è¯·æä¾›{api_description}")
        print(f"æ–¹æ³•1: è®¾ç½®ç¯å¢ƒå˜é‡ {default_api_key_env}")
        print(f"æ–¹æ³•2: ä½¿ç”¨ --api-key å‚æ•°")
        return
    
    # è·å–æ¨¡å‹
    model = args.model or default_model
    
    print(f"ğŸ¤– ä½¿ç”¨{args.provider}æä¾›å•†")
    print(f"ğŸ“± æ¨¡å‹: {model}")
    if args.base_url:
        print(f"ğŸŒ APIåœ°å€: {args.base_url}")
    
    # åˆ›å»ºå¢å¼ºå™¨
    enhancer = TestHciepTopologyEnhancer(
        provider=args.provider,
        api_key=api_key,
        base_url=args.base_url,
        model=model
    )
    
    # å¤„ç†æ–‡ä»¶
    if args.single_file:
        # å•æ–‡ä»¶æµ‹è¯•
        json_path = Path(args.single_file)
        if json_path.exists():
            enhancer.enhance_single_json(json_path)
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
    else:
        # æ‰¹é‡å¤„ç†
        if args.directory == "both":
            enhancer.enhance_both_directories(limit=args.limit)
        elif args.directory == "TEST":
            test_dir = Path("datasets/Huawei/TEST")
            if test_dir.exists():
                enhancer.enhance_directory(test_dir, limit=args.limit)
            else:
                print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        elif args.directory == "HCIEP":
            hciep_dir = Path("datasets/Huawei/HCIEP")
            if hciep_dir.exists():
                enhancer.enhance_directory(hciep_dir, limit=args.limit)
            else:
                print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {hciep_dir}")

if __name__ == "__main__":
    main()